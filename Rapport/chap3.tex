\chapter{The contributions}\label{sec:contributions}

%
\section{MRI Bias Field correction}

Bias correction is not efficient so we propose an other method, as part of the segmentation process.\\
Rescaling

\subsection{Interest}

algorithm is only accurate for small region bias correction, because au the gaussian model he uses.
Correction the bias in the whole volume first could enhance results.

\subsection{Our approach}

Gaussian distrib....
ITK filter
Automatic
\subsection{Results}
corrected not corrected
parameters explanation

%
\section{Intensity Normalization}
\subsection{Interest}
usefull if you need to do a lot of segmentations
enhance the rescaling..?
\subsection{Our approach}
background/brain
\subsection{Our implementation}
show results... corrected image...
%
\section{Class Distribution selection}\label{sec:CDS}
%
During parameters initialization, the user has to define each class distribution. The current methods presents some troubles so we present here a new approach to estimate each class distribution.
%
\subsection{Interest}
%
So far, the user haf two choices to define each class distribution. He could enter manually the intensities mean value and variance for each class, for each volume to be processed. This way, the user can be very precise and accurate when he defines each class. But it is very hard for the user to found the good mean value and variance for each class for each volume. Morever, each time he wants to process a new volume, he will have to redefine mean values and variances. This is not convenient and it can takes a ot of time. The next approch consisted in defining a class model by manual sampling. For each class, the user clics in the related part of the volume. With this methos, the problem is that you compute your mean value and variance using a few samples. Then, your mean values and variances are not accurate. That's why we proposed a new approach using a label map, to estimate each class model.
%
\subsection{Method used}
%
Create a label map. colors we choose a the same as the one we defined for each class.
then run algorithm which will estimate the mean value and covariance values.
\par
%
Algorithm..?
%
\par
Explain each colors
\par
\begin{figure}\centering
\begin{minipage}[c]{.45\textwidth}\centering
  \includegraphics[width=.95\textwidth]{Images/Screenshots/T1ForLabel.png}
  \caption{Axial view of a T1 volume without the label map.}\label{fig:T1ForLabel}
\end{minipage}\hfill
\begin{minipage}[c]{.45\textwidth}\centering
  \includegraphics[width=.95\textwidth]{Images/Screenshots/LabelT1.png}
  \caption{Axial view of a T1 volume with the label map.}\label{fig:LabelT1}
\end{minipage}
\begin{minipage}[c]{.45\textwidth}\centering
  \includegraphics[width=.95\textwidth]{Images/Screenshots/T2ForLabel.png}
  \caption{Axial view of a T2 volume without the label map.}\label{fig:T2ForLabel}
\end{minipage}\hfill
\begin{minipage}[c]{.45\textwidth}\centering
  \includegraphics[width=.95\textwidth]{Images/Screenshots/LabelT2.png}
  \caption{Axial view of a T2 volume with the label map.}\label{fig:LabelT2}
\end{minipage}
\end{figure}
%
\section{Class Distribution visualization}\label{sec:tables}

An important contribution is a tool which allows to visualize the classes to be segmented distribution, through 2 volumes.
\subsection{Interest}
As we discussed in 
%partDFSD 
the EMS algorithm requires variance and mean values for each class to be segmented. So far, the user defines these parameters by selecting samples on the dataset.
%
exampleSDFSF
%
A main issue is that user user can know if the pixels he selected are really representative or not of the class he wants to select. Thus, our objective  was to find a way to give the user if his samples are reprenstative of not of a tissue.
\subsection{Method used}
%display a 3d image to alow the user to see the distribution
%\subsubsection{ used}
%compute variance and covariance matrix
\subsubsection{Problem's description}
Here is a brief description of the situation to let you understanding the problem. As input we have N images, K classes to segment, and for each class a mean value $\mu$, a variance $\sigma$ and covariance $\zeta$. The covariance is estimated for each couple of images. We will come back on it later.
%
where
%
Using these informations, we had to find a way to give the user usefull informations about the class distribution.
\subsubsection{Choices}
Our first idea was to display gaussian curves in 3D, for each class. The X and Y axes would be the intensity ranges for the to images we want to use.
The problem with this representation is that it does not contain any information about the number o
%
f pixels .  3d too sophisticated...?
%
To solve this problem, we decided to divide the problem in two parts.
The first part will consist in creating a "temperature map" as background.
The second part will consists in displaying ellipses over this map. This will give the user a good information about how good his selection was.
\subsubsection{Background creation}
First of all, the background has to be created. This background is a "temperature map".
We can present it as a two dimensions array. The height and the lenght of the array depend of the intensity range of the 2 volumes we want to process.
Then, we fill the array in an easy but useful way. Each 
%
case
%
of the array contains the number of occurence of an intensity pair at the same position, through the 2 volumes.

\begin{minipage}{1\textwidth}
%
\hrule
\textbf{\\Algorithm 1:} \textsc{BackgroundCreation}(V1,V2)
\hrule
%variables definition
\textbf{\\define}  RangeI1 $\leftarrow$  intensity range in V1\\ 
\textbf{define}  RangeI2 $\leftarrow$  intensity range in V2\\ 
\textbf{define}  A(RangeI1,RangeI2) $\leftarrow$ background\\  
%
\textbf{for each} pixel \textbf{i} in V1\\
\textbf{for each} pixel \textbf{j} in V2\\
%
$\triangleright$A(i,j)=A(i,j)+1\\
%
\textbf{return} A\\
%
\hrule
%
\end{minipage}

\subsubsection{Ellipse representation}
We will first start we a brief
%
rappel..
%
The covariance matrix is \\
Representing ellipse associated to this covariance matrix.\\
Maximum variance axe.Eigen values\\
Algorithm used.
Big and small axes of the ellipse\\
\subsection{Results}
show result

\section{Global Prior Estimation}

The last contribution to the EMS is a tool which provides the user an easy and fast way to estimate the global prior weights (GPW).(ref ch2 ...)

\subsection{Presentation of the problem}
This contribution is usefull in many different ways.
When you run the segmentation process,at the 6th step of the process, you have to provide to the algorithm an estimation of the GPW for each node in the tree. 
First of all if there are a lot of structures to segment, they user can spend a lot of time during this step. Indeed, for each part of this tree strcuture, they have to define the GPW. Moreover, the user may not know at all which weights to choose. This new approach will provide the users a good estimations of the weights to use. We must also keep in mind that the end users are physicists. They might don't understand what the parameters meanings and providing them a visual feedback could help them a lot.
\subsection{Our approach}
We divided the problem in two parts. The first part will be about providing the user a real-time feedback regarding the GPW estimation.
The second part will consist in developping an algorithm which fills automatically the tree.
\subsubsection{Fast user feedback}
We can divide the feedback part in 3 steps: the histogram computation and utilisation, the multicolumn list and the labelmap generated.
The histogram allows the user to manual segment classes based on intensity.
The multicolumn list allows the user to change the order of the classes in the histogram.
The labelmap provides to the user a visual feedback, base on the segmentation realized in the histogram.
Using these three complementary tools, the user, even if he is not initiated can estimate easily, accurately and rapidely the GWP.
\\schema
\subsubsection{Global priors evaluation}
The algorithm used to estimate the weight of each node is iterative. It starts from the root and goes to the leaves. It evaluates the weight of the childs of the active node at each iteration. Here is a description of the algorithms used to compute the GPW of each node.\\
DEscirption algo 1\\\\
%
%
\begin{minipage}{1\textwidth}
%
\hrule
\textbf{\\Algorithm 1:} \textsc{TreeWeightEstimation}(R, W)
\hrule
%variables definition
\textbf{\\define}  C = CHILD(R) $\leftarrow$ set of childrens of root R\\ 
\textbf{define}  LEAF(C)      $\leftarrow$ set of leaves of tree with roots C\\ 
\textbf{define}  H            $\leftarrow$ set of structure-specific information defined by LEAF(C) for each leaf\\
%
\textbf{update} W in childrens of root R with the results of \textsc{WeightEstimation}(C,LEAF(C),H)\\
%
\textbf{for each} node R' in CHILD(R) that is not a leaf\\
%
$\triangleright$\textsc{TreeWeightEstimation}(R', W)\\
\hrule
%
\end{minipage}
%
\\\\\\Descripton algo2\\
The algorithm used estimates the global prior of the leaves of the current node, based on the number of pixel which belong to the child classes.
This number of pixels is calculated from the segmentation computed in the histogram.(CF ..)\\\\
%
\begin{minipage}{1\textwidth}
%
\hrule
\textbf{\\Algorithm 2:} \textsc{WeightEstimation}(C,LEAF(C), W,H)
\hrule
%variables definition
\textbf{\\define}  T $\leftarrow$ set of total weight of leaves in LEAF(C). Leaves weights are contained in H\\ 
\textbf{define}  E      $\leftarrow$ set of weight for each node of C\\ 
\textbf{for each}  node of C\\
$\triangleright$E=E+H : Get the total weight of each node\\
%
W=E/T\\
%
\textbf{return} (W)\\
\hrule
%
\end{minipage}
%

\subsection{Results and discussion}
As we can see, the results obtained are good and accurate.The time of processing is fast and most of the people are now able to understand these parameters, even they are not familiar with EMS. This is an intuitive way to get an estimation of the GPW parameters.\\
Of course some sfsdfs must be done.
If there is a strong bias in the images we process, the pixels of a same class will have different values. Then, a segmentation based on intensity will provide bad results. Moreover, if the user wants to segment 2 classes which have the same color, just using the spatial information for example, they won't be able to use it properly.Thus, the user must always keep in mind that it is just an estimation and that he has to check if the values are accurate.


